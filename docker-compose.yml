name: osss

x-kc-db-env: &kc_db_env
  KC_DB: ${KC_DB}
  KC_DB_URL_HOST: ${KC_DB_URL_HOST}
  KC_DB_URL_PORT: ${KC_DB_URL_PORT}
  KC_DB_URL_DATABASE: ${KC_DB_NAME}
  KC_DB_USERNAME: ${KC_DB_USERNAME}
  KC_DB_PASSWORD: ${KC_DB_PASSWORD}
  KC_DB_URL: "${KC_DB_URL}"
  # optional JDBC params; the importer will append them with a leading "?"
  KC_DB_URL_PROPERTIES: "${KC_DB_URL_PROPERTIES}"
  KC_LOG_LEVEL: "TRACE"
  QUARKUS_TRANSACTION_MANAGER_DEFAULT_TRANSACTION_TIMEOUT: "PT30M"
  QUARKUS_DATASOURCE_JDBC_ACQUISITION_TIMEOUT: "600s"
  QUARKUS_DATASOURCE_JDBC_BACKGROUND_VALIDATION_INTERVAL: "30S"
  QUARKUS_DATASOURCE_JDBC_VALIDATION_QUERY: "SELECT 1"
  QUARKUS_LOG_LEVEL: "INFO"
  KC_DB_POOL_INITIAL_SIZE: "1"
  KC_DB_POOL_MIN_SIZE: "1"
  KC_DB_POOL_MAX_SIZE: "5"
  KEYCLOAK_URL: "${KEYCLOAK_URL}"
  KEYCLOAK_ADMIN: "admin"
  KEYCLOAK_ADMIN_PASSWORD: "admin"
  KEYCLOAK_REALM: "OSSS"
  KEYCLOAK_HEALTH_URL: "${KEYCLOAK_HEALTH_URL}"
  # Force canonical base URL used in discovery/issuer:
  KC_FEATURES: "hostname:v1"


networks:
  osss-net: {}   # single definition



volumes:
  consul_data:
  kc_postgres_data:
  osss_postgres_data:
  redis-data:
  es-data:
  filebeat-data:




services:
  # HashiCorp Consul (dev mode) — service discovery, DNS, UI
  consul:
    image: hashicorp/consul:1.18
    profiles: ["app"]
    command: [ "agent","-dev","-client=0.0.0.0","-ui","-log-level=INFO" ]
    ports:
      - "8500:8500"          # HTTP UI/API
      - "8600:8600/tcp"      # DNS (TCP)
      - "8600:8600/udp"      # DNS (UDP)
    volumes:
      - consul_data:/consul/data
    networks: [ osss-net ]
    environment:
      # Registers services with Consul; Consul runs these checks from inside the container
      CONSUL_LOCAL_CONFIG: |
        {
          "datacenter": "dc1",
          "services": [
            {
              "name": "osss-postgres",
              "address": "osss_postgres",
              "port": 5432,
              "checks": [
                { "tcp": "osss_postgres:5432", "interval": "10s", "timeout": "2s" }
              ]
            },
            {
              "name": "kc-postgres",
              "address": "kc_postgres",
              "port": 5432,
              "checks": [
                { "tcp": "kc_postgres:5432", "interval": "10s", "timeout": "2s" }
              ]
            },
            {
              "name": "redis",
              "address": "redis",
              "port": 6379,
              "tags": ["cache", "redis"],
              "checks": [
                { "tcp": "redis:6379", "interval": "10s", "timeout": "2s" }
              ]
            },
            {
              "name": "vault",
              "address": "vault",
              "port": 8200,
              "tags": ["vault", "http"],
              "checks": [
                {
                  "http": "http://vault:8200/v1/sys/health?standbyok=true&sealedcode=503&standbycode=200&activecode=200",
                  "interval": "10s",
                  "timeout": "3s"
                }
              ]
            },
            {
              "name": "keycloak",
              "address": "keycloak",
              "port": 8080,
              "tags": ["keycloak", "http"],
              "checks": [
                {
                  "http": "http://keycloak:9000/health/ready",
                  "interval": "10s",
                  "timeout": "3s",
                  "DeregisterCriticalServiceAfter": "1m"
                }
              ]
            },
            {
              "name":"elasticsearch",
              "address":"elasticsearch",
              "port":9200,
              "checks":[
                {"http":"http://elasticsearch:9200","interval":"10s","timeout":"3s"}
              ]
            },
            {
              "name":"kibana",
              "address":"kibana",
              "port":5601,
              "checks":[
                {"http":"http://kibana:5601/api/status","interval":"10s","timeout":"3s"}
              ]
            }
          ]
        }

    healthcheck:
      test: [ "CMD-SHELL", "consul info >/dev/null 2>&1" ]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped



  app:
    profiles: ["app"]
    networks: [ osss-net ]
    build:
      context: .
      dockerfile: docker/app/Dockerfile
    command: >
      uvicorn src.OSSS.main:app
        --host 0.0.0.0 --port 8000 --reload
        --log-level debug
        --log-config /workspace/docker/logging.yaml
    working_dir: /workspace
    ports:
      - "8081:8000"     # host:container
    entrypoint: ["/usr/local/bin/app-entrypoint.sh"]

    volumes:
      - ./:/workspace:cached
      - ./docker/logging.yml:/workspace/docker/logging.yaml:ro
      - ./scripts/app-entrypoint.sh:/usr/local/bin/app-entrypoint.sh:ro   # file -> file ✅


    environment:
      # --- verbose logging knobs ---
      OSSS_VERBOSE_AUTH: "1"
      PYTHONUNBUFFERED: "1"
      PYTHONLOGLEVEL: DEBUG         # stdlib logging default
      LOG_LEVEL: DEBUG              # if your app reads this
      UVICORN_LOG_LEVEL: debug
      UVICORN_ACCESS_LOG: "1"

      KEYCLOAK_ISSUER: "${KEYCLOAK_ISSUER}"   # if your code also checks this
      KEYCLOAK_JWKS_URL: "${KEYCLOAK_JWKS_URL}"


      # Auth/OIDC stacks you might be using
      AUTHLIB_DEBUG: "1"            # Authlib (common with OIDC)
      OAUTHLIB_INSECURE_TRANSPORT: "1"  # allow http redirect/token exchange in dev

      # HTTP client debug (pick whichever your app uses)
      HTTPX_LOG_LEVEL: DEBUG
      REQUESTS_LOG_LEVEL: DEBUG

      # JWT/JWK libs often used under the hood
      JOSE_LOG_LEVEL: DEBUG
      JWcrypto_LOG_LEVEL: DEBUG

      HOST: 0.0.0.0
      PORT: "8000"
      PYTHONPATH: /workspace/src
      WATCHFILES_FORCE_POLLING: "true"
      # OIDC (unchanged)
      CORS_ALLOW_ORIGINS: "${CORS_ALLOW_ORIGINS}"
      CORS_ORIGINS: "${CORS_ORIGINS}"


      # external/public issuer (what tokens advertise)
      OIDC_ISSUER: "${OIDC_ISSUER}"

      # internal container-to-container paths (what your app should call)
      OIDC_DISCOVERY_URL_INTERNAL: "${OIDC_DISCOVERY_URL_INTERNAL}"
      OIDC_TOKEN_URL_INTERNAL: "${OIDC_TOKEN_URL_INTERNAL}"
      # optional (if you verify via JWKS directly)
      OIDC_JWKS_URL: "${OIDC_JWKS_URL}"

      # OIDC — must match how Keycloak issues tokens
      OIDC_CLIENT_ID: osss-api
      # If client is confidential:
      OIDC_CLIENT_SECRET: ${OIDC_CLIENT_SECRET:-password}
      # Public URLs your API advertises/uses for redirects
      OSSS_PUBLIC_BASE_URL: http://localhost:8081
      OIDC_REDIRECT_URL: http://localhost:8081/callback
      OIDC_LOGOUT_REDIRECT_URL: http://localhost:8081/
      # Helpful toggles while wiring up
      OIDC_VERIFY_AUD: "0"          # flip to "1" after adding audience mapper
      ALLOWED_CLOCK_SKEW: "60"
      # Sessions/Redis (you already fixed the host)
      REDIS_URL: redis://redis:6379/0
      SESSION_REDIS_HOST: redis
      SESSION_REDIS_PORT: "6379"
      KEYCLOAK_CLIENT_ID: osss-api
      KEYCLOAK_CLIENT_SECRET: password   # <-- use the real secret from Keycloak

      # This one is used by your async engine at runtime:
      ASYNC_DATABASE_URL: postgresql+asyncpg://${OSSS_DB_USER}:${OSSS_DB_PASSWORD}@osss_postgres:5432/${OSSS_DB_NAME}
      ALEMBIC_DATABASE_URL: postgresql+asyncpg://${OSSS_DB_USER}:${OSSS_DB_PASSWORD}@osss_postgres:5432/${OSSS_DB_NAME}

      OIDC_JWKS_URL_INTERNAL: ${OIDC_JWKS_URL_INTERNAL}

      # keep issuer verification on now that we pinned it correctly
      OIDC_VERIFY_ISS: "${OIDC_VERIFY_ISS}"

      MIGRATIONS_DIR: /app/src/OSSS/db/migrations   # <-- adjust to your repo
      REPO_ROOT: /app
      ALEMBIC_CMD: alembic
      ALEMBIC_INI: /app/alembic.ini
      OSSS_DB_PASSWORD: ${OSSS_DB_PASSWORD}
      OSSS_DB_NAME: ${OSSS_DB_NAME}
      OSSS_DB_USER: ${OSSS_DB_USER}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      DATABASE_URL: ${ASYNC_DATABASE_URL}   # keep them in lockstep



    depends_on:
      redis:
        condition: service_healthy   # ✅ wait for redis to be ready
      osss_postgres:
        condition: service_started
      keycloak:
        condition: service_healthy
    healthcheck: # ✅ let compose decide if the app is ready
      test: [ "CMD-SHELL","curl -fsS http://localhost:8000/healthz >/dev/null || exit 1" ]
      interval: 5s
      timeout: 3s
      retries: 90
      start_period: 20s



  web:
    profiles: ["app"]
    networks: [ osss-net ]
    build:
      context: ./src/osss-web
      dockerfile: ../../docker/osss-web/Dockerfile
    command: npm run dev -- --port 3000
    depends_on:
      app:
        condition: service_healthy
    environment:
      NODE_ENV: development
      # These make file watching reliable in containers:
      CHOKIDAR_USEPOLLING: "true"
      WATCHPACK_POLLING: "true"
      # Point web at the API container:
      OSSS_API_URL: "${OSSS_API_URL}"
    volumes:
      - ./src/osss-web:/app:cached
      - /app/node_modules
    working_dir: /app
    ports:
      - "3000:3000"
    labels:
      co.elastic.logs/enabled: "true"
      co.elastic.logs/json.add_error_key: "true"
      co.elastic.logs/json.overwrite_keys: "true"
      # custom dataset/type for web logs
      co.elastic.logs/processors.1.add_fields.fields.service: "osss-web"
      co.elastic.logs/processors.1.add_fields.fields.type: "frontend"
      co.elastic.logs/processors.1.add_fields.target: "event"

  osss_postgres:
    image: postgres:16-alpine
    profiles: [ "app" ]
    environment:
      # Primary bootstrap user for the cluster
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      POSTGRES_DB: "${POSTGRES_DB}"

      # App credentials you want created at init time
      OSSS_DB_USER: ${OSSS_DB_USER}
      OSSS_DB_PASSWORD: ${OSSS_DB_PASSWORD}
      OSSS_DB_NAME: ${OSSS_DB_NAME}

      # (optional) stricter auth for host connections on fresh init
      POSTGRES_INITDB_ARGS: "${POSTGRES_INITDB_ARGS}"

    networks: [ osss-net ]
    ports:
      - "5433:5432"
    volumes:
      - osss_postgres_data:/var/lib/postgresql/data
      # Mount an init script that creates role/db on first init only
      - ./scripts/init-osss.sh:/docker-entrypoint-initdb.d/20-init-osss.sh:ro
    healthcheck:
      # Use the configured superuser & db (NOTE the $$ to escape for Compose)
      test: [ "CMD-SHELL", "pg_isready -U \"$${POSTGRES_USER}\" -d \"$${POSTGRES_DB}\" -h 127.0.0.1 -p 5432 || exit 1" ]
      interval: 5s
      timeout: 5s
      retries: 20


  redis:
    image: redis:7-alpine
    profiles: ["app"]
    command: [ "redis-server", "--appendonly", "yes" ]
    ports:
      - "6379:6379"        # optional for host access; containers use 'redis:6379'
    networks: [ osss-net ]
    volumes:
      - redis-data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 20
    restart: unless-stopped


  kc_postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: ${KC_DB_NAME}
      POSTGRES_USER: ${KC_DB_USERNAME}
      POSTGRES_PASSWORD: ${KC_DB_PASSWORD}

    networks: [ osss-net ]
    volumes:
      - kc_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL","pg_isready -U ${KC_DB_USERNAME:-keycloak} -d ${KC_DB_NAME:-keycloak} -h 127.0.0.1 -p 5432 || exit 1" ]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 10s
    restart: always

  keycloak:
    build:
      context: .
      dockerfile: docker/keycloak/Dockerfile
    networks: [ osss-net ]
    environment:
      KC_DB: ${KC_DB}
      KC_DB_URL: jdbc:postgresql://${KC_DB_HOST}:${KC_DB_PORT}/${KC_DB_NAME}
      KC_DB_USERNAME: ${KC_DB_USERNAME}
      KC_DB_PASSWORD: ${KC_DB_PASSWORD}
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD}
      KC_HEALTH_ENABLED: "true"
      KC_HOSTNAME: "${KC_HOSTNAME}"
      KC_DB_SCHEMA: "${KC_DB_SCHEMA}"
      #KC_SPI_EVENTS_LISTENER_MAPPERSYNC_ENABLED: "false"

      # ✅ Force Quarkus to ignore any persistence.xml during the BUILD step
      QUARKUS_HIBERNATE_ORM_PERSISTENCE_XML_IGNORE: "true"

      JAVA_OPTS: "${JAVA_OPTS}"


      # Pool tuning (fine)
      KC_DB_POOL_INITIAL_SIZE: "20"
      KC_DB_POOL_MIN_SIZE: "20"
      KC_DB_POOL_MAX_SIZE: "50"


      # Optional verbose logging while you debug imports
      KC_LOG_LEVEL: "${KC_LOG_LEVEL}"

      # Make tokens & well-known advertise the external URL (what your app expects)
      KC_HOSTNAME_URL: "${KC_HOSTNAME_URL}"              # public URL (what users/browsers hit)
      KC_HOSTNAME_ADMIN_URL: "${KC_HOSTNAME_ADMIN_URL}"      # admin too

      # good practice when sitting behind any port mapping / proxy
      KC_PROXY: "${KC_PROXY}"
      # ensure HTTP is enabled in dev (since you’re not on TLS locally)
      KC_HTTP_ENABLED: "${KC_HTTP_ENABLED}"
      # optional: tolerate mixed inbound Host headers during dev
      KC_HOSTNAME_STRICT: "${KC_HOSTNAME_STRICT}"

      ADMIN_USER: "${KEYCLOAK_ADMIN}"
      ADMIN_PWD: "${KEYCLOAK_ADMIN_PASSWORD}"
      KC_URL: "${KC_URL}"

    volumes:
      # File(s) must live at /opt/keycloak/data/import inside the container and be .json
      - ./realm-export.json:/opt/keycloak/data/import/10-OSSS.json:ro
      - ./docker/keycloak/quarkus.properties:/opt/keycloak/conf/quarkus.properties:ro

      # If you split files, mount them all here with .json suffixes (Keycloak merges by realm name)
      # - ./OSSS-roles.json:/opt/keycloak/data/import/20-roles.json:ro
      # - ./OSSS-clients.json:/opt/keycloak/data/import/30-clients.json:ro
      # - ./OSSS-groups.json:/opt/keycloak/data/import/40-groups.json:ro
      # - ./OSSS-users.json:/opt/keycloak/data/import/50-users.json:ro
    ports:
      - "8080:8080"   # add this so host can reach keycloak:8080

    mem_limit: 2g             # honored by non-Swarm compose
    mem_reservation: 1g
    depends_on:
      kc_postgres:
        condition: service_healthy
    restart: always
    healthcheck:
      test: [ "CMD", "/opt/keycloak/healthcheck.sh" ]
      interval: 10s
      timeout: 10s
      retries: 190

  vault:
    #build:
    #  context: .                      # repo root
    #  dockerfile: docker/vault/Dockerfile
    image: hashicorp/vault:1.20.3
    profiles: ["app"]
    pull_policy: always
    container_name: vault
    ports: [ "8200:8200" ]
    cap_add: [ "IPC_LOCK" ]
    # ⬇️ Put Vault on the host network so `localhost:8080` is reachable
    networks: [ osss-net ]
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: "${VAULT_DEV_ROOT_TOKEN_ID}"
      VAULT_DEV_LISTEN_ADDRESS: "${VAULT_DEV_LISTEN_ADDRESS}"
      VAULT_UI: "${VAULT_UI}"
      # internal address used by other containers
      VAULT_API_ADDR: "${VAULT_API_ADDR}"
    depends_on:
      keycloak:
        condition: service_healthy
    command:
      - server
      - -dev
      - -dev-root-token-id=root
      - -dev-listen-address=0.0.0.0:8200
    healthcheck:
      test: [ "CMD-SHELL","wget -qO- http://127.0.0.1:8200/v1/sys/health | grep -q '\"initialized\":true'" ]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 10s
    restart: unless-stopped

  vault-oidc-setup:
    profiles: ["app"]
    build:
      context: .                      # repo root
      dockerfile: docker/vault-oidc-setup/Dockerfile
    container_name: vault-oidc-setup
    networks: [ osss-net ]
    depends_on:
      vault:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    environment:
      VERBOSE: "1"
      DEBUG: "1"
      # talk to Vault via service DNS inside the compose network
      VAULT_ADDR: "${VAULT_ADDR}"
      VAULT_TOKEN: "${VAULT_TOKEN:-root}"

      # Keycloak issuer (discovery URL without the /.well-known suffix)]
      OIDC_DISCOVERY_URL: "${OIDC_DISCOVERY_URL}"
      VAULT_OIDC_DISCOVERY_URL: "${VAULT_OIDC_DISCOVERY_URL}"
      VAULT_OIDC_CLIENT_ID: "${VAULT_OIDC_CLIENT_ID:-vault}"
      VAULT_OIDC_CLIENT_SECRET: "${VAULT_OIDC_CLIENT_SECRET:-password}"
      VAULT_OIDC_ROLE: "${VAULT_OIDC_ROLE:-vault}"
      VAULT_TOKEN_FILE: "/root/.vault-token"
      OIDC_ADMIN_GROUP: "/vault-admin"

      # Allow both 127.0.0.1 and localhost for UI & CLI
      VAULT_UI_REDIRECT_1: "http://127.0.0.1:8200/ui/vault/auth/oidc/oidc/callback"
      VAULT_UI_REDIRECT_2: "http://localhost:8200/ui/vault/auth/oidc/oidc/callback"
      VAULT_CLI_REDIRECT_1: "http://127.0.0.1:8250/oidc/callback"
      VAULT_CLI_REDIRECT_2: "http://localhost:8250/oidc/callback"

    volumes: [ "./scripts/vault-oidc-setup.sh:/setup.sh:ro","~/.vault-token:/root/.vault-token:ro" ]
    entrypoint: [ "/bin/sh","-lc","/setup.sh" ]
    restart: "no"


  vault-seed:
    image: alpine:3.20
    profiles: ["app"]
    env_file: .env
    networks: [ osss-net ]
    environment:
      VAULT_ADDR: "http://vault:8200"
      VAULT_TOKEN: "${VAULT_TOKEN:-root}"
      VAULT_KV_PATH: "${VAULT_KV_PATH:-app}"
      SEED_VAULT_TOKEN: "${VAULT_TOKEN:-root}"
      VERBOSE: "1"   # set to 0 to quiet logs
      DEBUG: "1"     # set to 1 for shell trace
    depends_on:
      vault:
        condition: service_healthy
    volumes:
      - ./scripts/seed-vault.sh:/usr/local/bin/seed-vault:ro
    entrypoint: [ "/bin/sh","-lc","/usr/local/bin/seed-vault" ]
    restart: "no"


  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.3
    profiles: ["app"]
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false         # dev only
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    networks: [ osss-net ]
    volumes:
      - es-data:/usr/share/elasticsearch/data
    healthcheck:
      test: [ "CMD-SHELL","curl -sf http://localhost:9200 >/dev/null || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.3
    profiles: ["app"]
    container_name: kibana
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_PUBLICBASEURL=http://localhost:5601
      - LOGGING_VERBOSE=true
      - XPACK_REPORTING_ENABLED=false
      - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=dev-dev-dev-dev-dev-dev-dev-dev1
      - NODE_OPTIONS=--max-old-space-size=512

    ports:
      - "5601:5601"
    networks: [ osss-net ]
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost:5601/api/status | grep -q 'available'" ]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 60s


  filebeat:
    image: docker.elastic.co/beats/filebeat:8.14.3
    profiles: ["app"]
    container_name: filebeat
    depends_on:
      elasticsearch:
        condition: service_healthy
    user: root
    networks: [ osss-net ]
    volumes:
      - ./filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: [ "--strict.perms=false" ]
    restart: unless-stopped
