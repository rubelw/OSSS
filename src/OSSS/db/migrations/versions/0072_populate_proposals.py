from __future__ import annotations

import os, csv, logging, random, re, secrets, hashlib, json
from pathlib import Path
from contextlib import nullcontext
from datetime import datetime, timezone
from itertools import cycle
from decimal import Decimal, InvalidOperation, ROUND_HALF_UP

from sqlalchemy.dialects import postgresql as pg

from alembic import op
import sqlalchemy as sa

# ---- Alembic identifiers ----
revision = "0072_populate_proposals"
# If your head before this migration is different, adjust the down_revision accordingly.
down_revision = "0071_populate_user_accts"
branch_labels = None
depends_on = None

log = logging.getLogger("alembic.runtime.migration")


# ---- Config / env toggles ----------------------------------------------------
LOG_LVL       = os.getenv("PROP_LOG_LEVEL", "INFO").upper()
LOG_SQL       = os.getenv("PROP_LOG_SQL", "0") == "1"
LOG_ROWS      = os.getenv("PROP_LOG_ROWS", "0") == "1"
ABORT_IF_ZERO = os.getenv("PROP_ABORT_IF_ZERO", "0") == "1"
PROP_ROWS     = int(os.getenv("PROP_ROWS", "50"))
PROP_SEED     = os.getenv("PROP_SEED")

CSV_ENV       = "PROPOSALS_CSV_PATH"
CSV_NAME      = "proposals.csv"

logging.getLogger("alembic.runtime.migration").setLevel(getattr(logging, LOG_LVL, logging.INFO))
engine_logger = logging.getLogger("sqlalchemy.engine")
engine_logger.setLevel(logging.INFO if LOG_SQL else getattr(logging, LOG_LVL, logging.INFO))

# ---- Tables ------------------------------------------------------------------
PROPOSALS_TBL = "proposals"
ORGS_TBL      = "organizations"
ASSOCS_TBL    = "education_associations"

# ---- Helpers -----------------------------------------------------------------
def _outer_tx(conn):
    try:
        if hasattr(conn, "get_transaction") and conn.get_transaction() is not None:
            return nullcontext()
        if hasattr(conn, "in_transaction") and conn.in_transaction():
            return nullcontext()
    except Exception:
        return nullcontext()
    return conn.begin()

def _per_row_tx(conn):
    try:
        return conn.begin_nested()
    except Exception:
        return nullcontext()

def _default_output_path(name: str) -> Path:
    envp = os.getenv(CSV_ENV)
    if envp:
        p = Path(envp)
        return (p / name) if p.is_dir() else p
    return Path(__file__).resolve().with_name(name)

def _write_csv(bind) -> Path:
    """
    Always (re)write proposals.csv with PROP_ROWS rows using random existing IDs
    from organizations and associations. If either table is empty, write headers only.
    """
    out = _default_output_path(CSV_NAME)
    out.parent.mkdir(parents=True, exist_ok=True)

    org_ids = [str(r[0]) for r in bind.execute(sa.text(f"SELECT id FROM {ORGS_TBL} ORDER BY id")).fetchall()]
    assoc_ids = [str(r[0]) for r in bind.execute(sa.text(f"SELECT id FROM {ASSOCS_TBL} ORDER BY id")).fetchall()]

    fields = ["organization_id", "association_id", "title", "summary", "status", "submitted_at", "attributes"]

    if not org_ids or not assoc_ids:
        log.warning("[%s] orgs=%d, assocs=%d — writing header-only CSV (%s) and skipping population.",
                    revision, len(org_ids), len(assoc_ids), out)
        with out.open("w", newline="", encoding="utf-8") as f:
            csv.writer(f).writerow(fields)
        return out

    rng = random.Random(PROP_SEED)
    now_iso = datetime.now(timezone.utc).isoformat()

    # To avoid enum mismatch risk, keep status "draft" for all rows (always valid if default).
    status_value = "draft"

    with out.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(fields)
        for i in range(PROP_ROWS):
            org = rng.choice(org_ids)
            assoc = rng.choice(assoc_ids)
            title = f"Seeded Proposal #{i+1} ({org[:8]}→{assoc[:8]})"
            summary = "Autogenerated by migration {rev} for seeding.".format(rev=revision)
            submitted_at = ""  # keep blank for 'draft' (nullable)
            attrs = {"seed": revision, "row": i+1}

            w.writerow([org, assoc, title, summary, status_value, submitted_at, json.dumps(attrs)])

    log.info("[%s] wrote %d rows -> %s", revision, PROP_ROWS, out)
    return out

def _open_csv(csv_path: Path):
    f = csv_path.open("r", encoding="utf-8", newline="")
    reader = csv.DictReader(f)
    log.info("[%s] CSV headers: %s (%s)", revision, reader.fieldnames, csv_path)
    return reader, f

# ---- Insert builder ----------------------------------------------------------
def _insert_sql(bind):
    insp = sa.inspect(bind)
    cols = {c["name"] for c in insp.get_columns(PROPOSALS_TBL)}

    ins_cols, vals = ["id"], ["gen_random_uuid()"]

    def add(col):
        if col in cols:
            ins_cols.append(col)
            vals.append(f":{col}")

    for c in ("organization_id","association_id","title","summary","status","submitted_at","attributes"):
        add(c)
    if "created_at" in cols: ins_cols.append("created_at"); vals.append("now()")
    if "updated_at" in cols: ins_cols.append("updated_at"); vals.append("now()")

    sql = sa.text(f"INSERT INTO {PROPOSALS_TBL} ({', '.join(ins_cols)}) VALUES ({', '.join(vals)})")
    # Ensure attributes binds as JSON/JSONB if present
    if "attributes" in cols:
        sql = sql.bindparams(sa.bindparam("attributes", type_=pg.JSONB if bind.dialect.name == "postgresql" else sa.JSON))
    return sql, cols

# ---- Migration ---------------------------------------------------------------
def upgrade() -> None:
    bind = op.get_bind()
    insp = sa.inspect(bind)

    # Always (re)generate CSV
    csv_path = _write_csv(bind)
    reader, fobj = _open_csv(csv_path)

    # Cleanup previously-seeded rows by this revision (safe re-run)
    if insp.has_table(PROPOSALS_TBL) and bind.dialect.name == "postgresql":
        try:
            res = bind.execute(sa.text(
                f"DELETE FROM {PROPOSALS_TBL} WHERE attributes ->> 'seed' = :rev"
            ), {"rev": revision})
            try:
                log.info("[%s] removed %s previously seeded rows", revision, res.rowcount)
            except Exception:
                pass
        except Exception:
            log.exception("[%s] pre-clean of seeded rows failed (non-fatal)", revision)

    insert_stmt, cols = _insert_sql(bind)

    total = inserted = skipped = 0
    try:
        with _outer_tx(bind):
            for idx, raw in enumerate(reader, start=1):
                total += 1
                row = { (k.strip() if isinstance(k,str) else k): (v.strip() if isinstance(v,str) else v)
                        for k, v in (raw or {}).items() }

                if not row:  # empty
                    continue

                org_id   = row.get("organization_id") or None
                assoc_id = row.get("association_id") or None
                title    = row.get("title") or None
                if not (org_id and assoc_id and title):
                    skipped += 1
                    if LOG_ROWS:
                        log.warning("[%s] row %d missing org/assoc/title — skipping: %r", revision, idx, row)
                    continue

                # Parse JSON attributes
                attrs_val = None
                raw_attrs = row.get("attributes")
                if raw_attrs:
                    try:
                        attrs_val = json.loads(raw_attrs)
                    except Exception:
                        attrs_val = {"seed": revision, "raw_attributes": raw_attrs}

                params = {
                    "organization_id": org_id,
                    "association_id": assoc_id,
                    "title": title,
                    "summary": row.get("summary") or None,
                    "status": (row.get("status") or "draft"),
                    "submitted_at": (row.get("submitted_at") or None),
                    "attributes": attrs_val,
                }
                # Keep only real columns
                params = {k: v for k, v in params.items() if k in cols}

                try:
                    with _per_row_tx(bind):
                        bind.execute(insert_stmt, params)
                        inserted += 1
                        if LOG_ROWS:
                            log.info("[%s] row %d inserted OK (%s)", revision, idx, title)
                except Exception:
                    skipped += 1
                    log.exception("[%s] row %d insert failed; params=%r", revision, idx, params)
    finally:
        try:
            fobj.close()
        except Exception:
            pass

    log.info("[%s] CSV rows=%d, inserted=%d, skipped=%d (file=%s)", revision, total, inserted, skipped, csv_path)
    if ABORT_IF_ZERO and inserted == 0:
        raise RuntimeError(f"[{revision}] No rows inserted; enable PROP_LOG_ROWS=1 for per-row diagnostics.")

def downgrade() -> None:
    bind = op.get_bind()
    try:
        res = bind.execute(sa.text(
            f"DELETE FROM {PROPOSALS_TBL} WHERE attributes ->> 'seed' = :rev"
        ), {"rev": revision})
        try:
            log.info("[%s] downgrade: deleted %s seeded rows", revision, res.rowcount)
        except Exception:
            pass
    except Exception:
        log.exception("[%s] downgrade best-effort delete failed", revision)